{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Классификация FashionMNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p_RpCoxwI-3t"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xisOZZqHI-30"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GmtiO_TeI-32",
        "outputId": "b8f56e01-954e-427e-c0f3-d609d90037eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-10 19:48:11--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-10 19:48:12--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-04-10 19:48:12 (89.4 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nHrHe3rxI-33"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qqU-mVqQI-36"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "aYcL28OsgSq8",
        "outputId": "0ae7a4a6-f5ce-4e06-e32e-9924c04a0e80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.4MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 208kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.85MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 9.96MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 0')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvMNISTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=2, padding=2)\n",
        "        self.conv2 = nn.Conv2d(16, 48, kernel_size=5, stride=2, padding=2)\n",
        "        self.conv3 = nn.Conv2d(48, 256, kernel_size=7, stride=1, padding=0)\n",
        "\n",
        "        self.fc = nn.Linear(256, 10)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        #[batch, 1, 28, 28]\n",
        "        x = self.activation(self.conv1(x))  # [batch, 16, 14, 14]\n",
        "        x = self.activation(self.conv2(x))  # [batch, 48, 7, 7]\n",
        "        x = self.activation(self.conv3(x))  # [batch, 256, 1, 1]\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # [batch, 256]\n",
        "        x = self.fc(x)  # [batch, 10]\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ELN6qeBDPMNz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_1 = ConvMNISTNet()\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "outputId": "c92b02f8-863f-406b-8a81-bc98f58476c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvMNISTNet(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  (conv2): Conv2d(16, 48, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  (conv3): Conv2d(48, 256, kernel_size=(7, 7), stride=(1, 1))\n",
              "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (activation): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "683903c0-13f5-472a-baff-b42121593945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "outputId": "68078f9b-21d4-4045-a159-5d6e5b5936e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100: 100%|██████████| 1782/1782 [00:13<00:00, 127.71it/s, loss=0.2020]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.4394, Val Loss: 0.3343, Val Acc: 87.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100: 100%|██████████| 1782/1782 [00:13<00:00, 127.79it/s, loss=0.1244]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss: 0.2943, Val Loss: 0.2868, Val Acc: 89.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100: 100%|██████████| 1782/1782 [00:15<00:00, 114.70it/s, loss=0.2899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss: 0.2470, Val Loss: 0.2580, Val Acc: 90.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100: 100%|██████████| 1782/1782 [00:14<00:00, 125.35it/s, loss=0.1714]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss: 0.2145, Val Loss: 0.2538, Val Acc: 90.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100: 100%|██████████| 1782/1782 [00:14<00:00, 125.42it/s, loss=0.0817]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss: 0.1849, Val Loss: 0.2458, Val Acc: 91.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100: 100%|██████████| 1782/1782 [00:14<00:00, 119.25it/s, loss=0.9314]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss: 0.1591, Val Loss: 0.2479, Val Acc: 91.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100: 100%|██████████| 1782/1782 [00:14<00:00, 125.93it/s, loss=0.2710]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss: 0.1360, Val Loss: 0.2489, Val Acc: 90.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100:   5%|▌         | 98/1782 [00:01<00:21, 79.31it/s, loss=0.0102]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-14e231a8efb6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprogress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Epoch {epoch+1}/{num_epochs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RecordFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_as_effectful_op_temporarily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallthrough_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfallthrough_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "train_dataset = train_fmnist_data\n",
        "train_size = int(0.95 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_task_1 = ConvMNISTNet().to(device)\n",
        "optimizer = optim.Adam(model_task_1.parameters(), eps=1e-4, weight_decay=1e-5, betas=(0.9, 0.999))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 100\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_task_1.train()\n",
        "    train_loss = 0.0\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "    for images, labels in progress_bar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_task_1(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "    # Валидация\n",
        "    model_task_1.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model_task_1(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f'Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model_task_1.state_dict(), 'best_mnist_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "outputId": "d128c36d-bd94-4968-cca3-dc7624b0acb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.95953\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "outputId": "098f0c1d-9af2-40be-f302-00ae73000c80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9059\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHNRQUT_I-4E"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ca09TuWKI-4E",
        "outputId": "b1193e56-54fb-4b5e-eebe-06c2eab897df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `/content/submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"/content/hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `/content/hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"/content/hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "}\n",
        "\n",
        "with open(\"/content/submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `/content/submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwlmThQCI-4F"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}